import numpy as np
import os
import math
import datetime
import subprocess
import progressbar
from scipy import stats

import src.text as text
import src.bow_feat as feat
import src.cv_partition as cv
import src.sign_test as st

'''
The SVM classifier is achieved by using SVM-Light implmenetation by Joachims, 1999
subporocess.run(args) run the command described by args. Wait for command to complete, then return a CompletedProcess instance
'''

'''
HOW TO USE SVM-LIGHT
svm_learn example1/train.dat example1/model
svm_classify example1/test.dat example1/model example1/predictions
'''


# prepare the train/text data for SVM classifier
def prepare_data_svm(train_test_matrix, train_test_size, test=False):
    # para train_test_matrix: training/test matrix generated by bow_feat
    # para train_test_size: training/test set size
    # para test: either training data or test data preparation
    # type train_test_matrix: list(list(integer))
    path = './models/svm_models/test.dat' if test else './models/svm_models/train.dat'

    # training or test vector of labels 
    train_test_class_vector = np.hstack((np.ones(train_test_size)*-1, np.ones(train_test_size)))
    train_test_data = list()
    feat_size = len(train_test_matrix[0])

    bar = progressbar.ProgressBar()
    with open(path, 'w', encoding='utf-8') as f:
        for i in bar(range(len(train_test_class_vector))):
            train_test_data.append(["%d:%f" % (j+1, train_test_matrix[i][j]) for j in range(feat_size)])
            # write the label and data to file
            f.write("%d " % train_test_class_vector[i])
            for j in range(len(train_test_data[i])):
                f.write("%s " % train_test_data[i][j])
            f.write("\n")
    f.close()


# save the readme file of SVM model
def save_readme():
    readme_notes = np.array(["This SVM model is trained on ", str(datetime.datetime.now())])
    np.savetxt("./models/svm_models/readme.txt", readme_notes, fmt="%s")


# train the SVM-Light classifier
def train_svm_classifier():
    # check if files available
    assert os.path.isfile("./svm-light/svm_learn"), "SVM Light source code missing"
    assert os.path.isfile("./models/svm_models/train.dat"), "SVM training data missing"
    # run the SVM-Light classifier
    subprocess.run(["./svm-light/svm_learn", "./models/svm_models/train.dat", "./models/svm_models/model"])
    save_readme()
    

# test the SVM-Light classifier
def test_svm_classifier():
    # check if files available
    assert os.path.isfile("./svm-light/svm_classify"), "SVM Light source code missing"
    assert os.path.isfile("./models/svm_models/test.dat"), "SVM test data missing"
    assert os.path.isfile("./models/svm_models/model"), "SVM model data missing (SVM classifier is perhaps not trained yet.)"
    # run the SVM-Light classifier
    subprocess.run(["./svm-light/svm_classify", "./models/svm_models/test.dat", "./models/svm_models/model", "./models/svm_models/predictions"])


def SVM_classifier(feature_type, cv_part=False, train_size_cv=None, test_size_cv=None, reviews_train_cv=None, reviews_test_cv=None):
    # para feature_type: unigram or bigram (n-gram bag of words)
    # para cv_part: whether or not is is partitioned with cross-validation
    print("\nSVM-Light Classifier on sentiment detection running\n\npreparing data ...")
    if not cv_part:
        train_size, test_size, reviews_train, reviews_test = cv.prepare_data()
    else:
        train_size, test_size, reviews_train, reviews_test = train_size_cv, test_size_cv, reviews_train_cv, reviews_test_cv

    print("\nfinding the corpus for the classifier ...")
    # full vocabulary for the training reviews (frequency cutoff implemented)
    if feature_type == 'unigram':
        full_vocab = feat.get_vocab(reviews_train, cutoff_threshold=9)
    elif feature_type == 'bigram':
        full_vocab = feat.get_vocab_bigram(reviews_train, cutoff_threshold=14)
    else:
        full_vocab = feat.get_vocab(reviews_train, cutoff_threshold=9) + feat.get_vocab_bigram(reviews_train, cutoff_threshold=14)
    vocab_length = len(full_vocab)
    print("\n#features is ", vocab_length)

    print("\ngenerate the training matrix ...")
    # training matrix of data
    if feature_type == 'unigram':
        train_matrix = feat.bag_words2vec_unigram(full_vocab, reviews_train)
    elif feature_type == 'bigram':
        train_matrix = feat.bag_words2vec_bigram(full_vocab, reviews_train)
    else:
        train_matrix = feat.concatenate_feat(feat.bag_words2vec_unigram(
            full_vocab, reviews_train), feat.bag_words2vec_bigram(full_vocab, reviews_train))
    print('\ndescription of training matrix', stats.describe(train_matrix))

    print("\ngenerate the test matrix ...")
    # testing matrix of data
    if feature_type == 'unigram':
        test_matrix = feat.bag_words2vec_unigram(full_vocab, reviews_test)
    elif feature_type == 'bigram':
        test_matrix = feat.bag_words2vec_bigram(full_vocab, reviews_test)
    else:
        test_matrix = feat.concatenate_feat(feat.bag_words2vec_unigram(
            full_vocab, reviews_test), feat.bag_words2vec_bigram(full_vocab, reviews_test))
    print('\ndescription of test matrix', stats.describe(test_matrix))
    
    print("\nprepare the data for the SVM-Light classifier ...")
    prepare_data_svm(train_matrix, train_size)
    prepare_data_svm(test_matrix, test_size, test=True)
    print("\ndata preparation, DONE")

    print("\ntrain the SVM-Light classifier ... \n")
    train_svm_classifier()
    print("\ntraining, DONE.")
    
    print("\ntest the SVM-Light classifier ... \n")
    test_svm_classifier()
    print("\ntest, DONE.")

    print("\nclassification results are shown as above")