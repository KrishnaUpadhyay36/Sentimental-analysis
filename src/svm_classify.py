import numpy as np
import os
import math
import datetime
import subprocess
import progressbar
import statsmodels.api
from scipy import stats
from sklearn import svm
from sklearn import metrics
from sklearn.model_selection import GridSearchCV
from smart_open import smart_open

import src.text as text
import src.bow_feat as feat
import src.doc2vec as doc2vec
import src.cv_partition as cv
import src.stats_test as st

'''
The SVM classifier is achieved by using SVM-Light implmenetation by Joachims, 1999
subporocess.run(args) run the command described by args. Wait for command to complete, then return a CompletedProcess instance

HOW TO USE SVM-LIGHT
svm_learn example1/train.dat example1/model
svm_classify example1/test.dat example1/model example1/predictions
'''

SVM_BOW_PATH = './models/svm_models/bow_svm/'
SVM_DOC2VEC_PATH = './models/svm_models/doc2vec_svm/'
SVM_PARA_GRID_PATH = './results/gridsearch_doc2vec.txt'


# prepare the train/text data for SVM classifier
def prepare_data(train_test_matrix, train_test_size, if_doc2vec, test=False):
    # para train_test_matrix: training/test matrix generated by bow_feat / doc2vec
    # para train_test_size: training/test set size
    # para if_doc2vec: bow features or doc2vec embeddings
    # para test: either training data or test data preparation
    # type train_test_matrix: list(list(int/float))
    if not if_doc2vec:
        path = SVM_BOW_PATH + 'test.dat' if test else SVM_BOW_PATH + 'train.dat'
    else:
        path = SVM_DOC2VEC_PATH + 'test.dat' if test else SVM_DOC2VEC_PATH + 'train.dat'
    
    if os.path.isfile(path):
        os.remove(path) # delete the old file

    # training or test vector of labels 
    train_test_labels = np.hstack((np.ones(train_test_size)*-1, np.ones(train_test_size)))
    train_test_data = list()
    feat_size = len(train_test_matrix[0])

    bar = progressbar.ProgressBar()
    with smart_open(path, 'w', encoding='utf-8') as f:
        for i in bar(range(len(train_test_labels))):
            train_test_data.append(["%d:%f" % (j+1, train_test_matrix[i][j]) for j in range(feat_size)])
            # write the label and data to file
            f.write("%d " % train_test_labels[i])
            for k in range(len(train_test_data[i])):
                f.write("%s " % train_test_data[i][k])
            f.write("\n")


# save the readme file of SVM model
def save_readme(if_doc2vec=False):
    # para if_doc2vec: bow features or doc2vec embeddings
    readme_notes = np.array(["This SVM model is trained on ", str(datetime.datetime.now())])
    if if_doc2vec:
        np.savetxt(SVM_DOC2VEC_PATH + "readme.txt", readme_notes, fmt="%s")
    else:
        np.savetxt(SVM_BOW_PATH + "readme.txt", readme_notes, fmt="%s")


# train the SVM-Light classifier 
def train_svm_classifier(if_doc2vec):
    # para if_doc2vec: bow features or doc2vec embeddings
    svm_path = SVM_DOC2VEC_PATH if if_doc2vec else SVM_BOW_PATH
    # check if files available
    assert os.path.isfile("./svm-light/svm_learn"), "SVM Light source code missing"
    assert os.path.isfile(svm_path + "train.dat"), "SVM training data missing"
    # run the SVM-Light classifier
    subprocess.run(["./svm-light/svm_learn", "-m", "100", svm_path + "train.dat", svm_path + "model"])
    save_readme(if_doc2vec)
    

# test the SVM-Light classifier 
def test_svm_classifier(if_doc2vec):
    # para if_doc2vec: bow features or doc2vec embeddings
    svm_path = SVM_DOC2VEC_PATH if if_doc2vec else SVM_BOW_PATH
    # check if files available
    assert os.path.isfile("./svm-light/svm_classify"), "SVM Light source code missing"
    assert os.path.isfile(svm_path + "test.dat"), "SVM test data missing"
    assert os.path.isfile(svm_path + "model"), "SVM model data missing (SVM classifier is perhaps not trained yet.)"
    # run the SVM-Light classifier
    subprocess.run(["./svm-light/svm_classify", svm_path + "test.dat", svm_path + "model", svm_path + "predictions"])


def SVM_classifier(feature_type, cv_part=False, if_doc2vec=False, model_no=1, train_size_cv=None, test_size_cv=None, reviews_train_cv=None, reviews_test_cv=None):
    # para feature_type: unigram or bigram (n-gram bag of words)
    # para cv_part: whether or not is partitioned with cross-validation
    # para if_doc2vec: bow features or doc2vec embeddings
    print("\nSVM-Light Classifier on sentiment detection running\n\npreparing data ...")
    if not cv_part:
        train_size, test_size, reviews_train, reviews_test = cv.prepare_data()
    else:
        train_size, test_size, reviews_train, reviews_test = train_size_cv, test_size_cv, reviews_train_cv, reviews_test_cv

    if not if_doc2vec:
        print("\nfinding the corpus for the classifier ...")
        # full vocabulary for the training reviews (frequency cutoff implemented)
        if feature_type == 'unigram':
            full_vocab = feat.get_vocab(reviews_train, cutoff_threshold=9)
        elif feature_type == 'bigram':
            full_vocab = feat.get_vocab_bigram(reviews_train, cutoff_threshold=14)
        else:
            full_vocab = feat.get_vocab(reviews_train, cutoff_threshold=9) + feat.get_vocab_bigram(reviews_train, cutoff_threshold=14)
        vocab_length = len(full_vocab)
        print("\n#features is ", vocab_length)

        print("\ngenerate the BOW-based training matrix ...")
        # training matrix of data
        if feature_type == 'unigram':
            train_matrix = feat.bag_words2vec_unigram(full_vocab, reviews_train)
        elif feature_type == 'bigram':
            train_matrix = feat.bag_words2vec_bigram(full_vocab, reviews_train)
        else:
            train_matrix = feat.concatenate_feat(feat.bag_words2vec_unigram(
                full_vocab, reviews_train), feat.bag_words2vec_bigram(full_vocab, reviews_train))
        print('\ndescription of training matrix', stats.describe(train_matrix))

        print("\ngenerate the BOW-based test matrix ...")
        # testing matrix of data
        if feature_type == 'unigram':
            test_matrix = feat.bag_words2vec_unigram(full_vocab, reviews_test)
        elif feature_type == 'bigram':
            test_matrix = feat.bag_words2vec_bigram(full_vocab, reviews_test)
        else:
            test_matrix = feat.concatenate_feat(feat.bag_words2vec_unigram(
                full_vocab, reviews_test), feat.bag_words2vec_bigram(full_vocab, reviews_test))
        print('\ndescription of test matrix', stats.describe(test_matrix))
    
    else:
        print("\ninfer document embeddings with pre-trained no.%d doc2vec model ..." % model_no)
        train_matrix, train_labels = doc2vec.infer_embedding(model_no, reviews_train, train_size)
        test_matrix, test_labels = doc2vec.infer_embedding(model_no, reviews_test, test_size)

    print("\nprepare the data for the SVM-Light classifier ...")
    prepare_data(train_matrix, train_size, if_doc2vec)
    prepare_data(test_matrix, test_size, if_doc2vec, test=True)
    print("\ndata preparation, DONE")

    print("\ntrain the SVM-Light classifier ... \n")
    train_svm_classifier(if_doc2vec)
    print("\ntraining, DONE.")
    
    print("\ntest the SVM-Light classifier ... \n")
    test_svm_classifier(if_doc2vec)
    print("\ntest, DONE.")

    print("\nclassification results are shown as above")


def SVM_classifier_sklearn(model_no):
    # para model_no: which Doc2Vec model to use
    train_size, test_size, reviews_train, reviews_test = cv.prepare_data()
    train_matrix, train_labels = doc2vec.infer_embedding(model_no, reviews_train, train_size)
    test_matrix, test_labels = doc2vec.infer_embedding(model_no, reviews_test, test_size)
    X_train, y_train, X_test, y_test = train_matrix, train_labels, test_matrix, test_labels
    print("\ntrain the sklearn SVM classifier (with doc2vec embeddings) ... \n")
    svm_doc2vec = svm.SVC(kernel='rbf', C=10, degree=3, gamma='auto')
    svm_doc2vec.fit(X_train, y_train)
    print("\ntraining, DONE.")
    print("\ntest the sklearn SVM classifier (with doc2vec embeddings) ... \n")
    y_pred = svm_doc2vec.predict(X_test)
    print(metrics.classification_report(y_test, y_pred))
    print("Overall accuracy: ", round(metrics.accuracy_score(y_test, y_pred), 2))


def SVM_grid_search(model_no):
    # para model_no: which Doc2Vec model to use
    train_size, test_size, reviews_train, reviews_test = cv.prepare_data()
    train_matrix, train_labels = doc2vec.infer_embedding(model_no, reviews_train, train_size)
    test_matrix, test_labels = doc2vec.infer_embedding(model_no, reviews_test, test_size)
    X_train, y_train, X_test, y_test = train_matrix, train_labels, test_matrix, test_labels
    print("\nrun the Grid Search for SVM classifier (with doc2vec embeddings) ... \n")
    tuned_parameters = [
        {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},
        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}
        ]
    clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=10, n_jobs=12, verbose=10)
    clf.fit(X_train, y_train)
    print("\ngrid search, DONE.")
    print("\ngrid search results are listed as follows.")
    print(clf.best_params_, clf.best_score_)
    sorted(clf.cv_results_.keys())
    
    with smart_open(SVM_PARA_GRID_PATH, 'a+', encoding='utf-8') as f:
        line = str(doc2vec.load_model(model_no)) + str(clf.best_params_) + "\t" + str(clf.best_score_)
        f.write(line)
        f.write("\n")
    print("\ngrid search results are written to file.")


def logistic_predictor(model_no):
    train_size, test_size, reviews_train, reviews_test = cv.prepare_data()
    train_matrix, train_labels = doc2vec.infer_embedding(model_no, reviews_train, train_size)
    test_matrix, test_labels = doc2vec.infer_embedding(model_no, reviews_test, test_size)
    # X_train, y_train, X_test, y_test = train_matrix, train_labels, test_matrix, test_labels

    logit = statsmodels.api.Logit(train_labels, train_matrix)
    predictor = logit.fit(disp=0)
    train_prediction = predictor.predict(train_matrix)
    cor = sum(np.rint(train_prediction) == train_labels)
    print("training accuracy", cor/len(train_prediction))
    test_predictions = predictor.predict(test_matrix)
    corrects = sum(np.rint(test_predictions) == test_labels)
    errors = len(test_predictions) - corrects
    error_rate = float(errors) / len(test_predictions)
    print("accuracy", corrects/len(test_predictions))


'''
./svm-light/svm_learn [option] example_file model_file

-t (int)
0: linear (default)
1: polynomial (s a*b+c)^d
2. radial basis function exp(-gamma ||a-b||^2)
3. sigmoid tanh(s a*b + c)
4. user defined kernel from kernel.h

-g (float)
parameter gamma in rbf kernel

'''